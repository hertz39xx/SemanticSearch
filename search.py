import faiss
import json
from embedding import embed_texts
import tiktoken
import time
import numpy as np
from openai import OpenAI
import os
import dotenv

dotenv.load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# å¿«å–è®Šæ•¸ï¼Œé¿å…é‡è¤‡è¼‰å…¥
_index_cache = {}
_metadata_cache = {}

def search_faiss_with_cost(query, index_path="book.index", meta_path="book_metadata.json", top_k=3):
    start_total = time.time()
    
    # è¼‰å…¥ index & metadata (ä½¿ç”¨å¿«å–)
    index_load_start = time.time()
    if index_path not in _index_cache:
        _index_cache[index_path] = faiss.read_index(index_path)
    if meta_path not in _metadata_cache:
        with open(meta_path, "r", encoding="utf-8") as f:
            _metadata_cache[meta_path] = json.load(f)
    
    index_load_time = time.time() - index_load_start
    print(f"ğŸ“ Index è¼‰å…¥æ™‚é–“: {index_load_time:.3f}s")
    
    index = _index_cache[index_path]
    chunks = _metadata_cache[meta_path]

    # æŸ¥è©¢ embedding èˆ‡æˆæœ¬
    q_vec, embed_cost, embed_time = embed_query_with_cost(query)

    # æœå°‹æœ€è¿‘é„°
    search_start = time.time()
    D, I = index.search(np.array([q_vec]), top_k)
    search_time = time.time() - search_start
    print(f"ğŸ” FAISS æœå°‹æ™‚é–“: {search_time:.3f}s")

    results = []
    for idx in I[0]:
        if idx < len(chunks):
            results.append(chunks[idx])

    total_time = time.time() - start_total
    
    print(f"ğŸ” æœå°‹å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} ç­†ç›¸ä¼¼å…§å®¹")
    print(f"ğŸ’µ æœ¬æ¬¡æŸ¥è©¢ç¸½æˆæœ¬ï¼š${embed_cost:.8f} (embedding cost only)")
    print(f"ğŸ•’ ç¸½è€—æ™‚ï¼š{total_time:.2f}s")
    print(f"ğŸ“Š æ™‚é–“åˆ†è§£ï¼šIndexè¼‰å…¥({index_load_time:.3f}s) + Embedding({embed_time:.3f}s) + æœå°‹({search_time:.3f}s)")

    return {
        "results": results,
        "embedding_cost_usd": embed_cost,
        "embedding_time_sec": embed_time,
        "total_time_sec": total_time,
        "index_load_time_sec": index_load_time,
        "search_time_sec": search_time
    }

def count_tokens(text, model="text-embedding-3-small"):
    enc = tiktoken.encoding_for_model(model)
    return len(enc.encode(text))

def embed_query_with_cost(query, model="text-embedding-3-small"):
    """
    å°‡ä½¿ç”¨è€…æŸ¥è©¢è½‰æˆ embeddingï¼ŒåŒæ™‚è¨ˆç®—èŠ±è²»ã€‚
    """
    start = time.time()
    token_count = count_tokens(query, model=model)

    response = client.embeddings.create(
        model=model,
        input=query
    )
    end = time.time()

    embedding = np.array(response.data[0].embedding, dtype="float32")

    # æˆæœ¬è¨ˆç®—
    price_per_1k = 0.00002  # text-embedding-3-small å–®åƒ¹
    cost = (token_count / 1000) * price_per_1k

    print(f"ğŸ§  Query Tokens: {token_count}")
    print(f"ğŸ’° Embedding Cost: ${cost:.8f} USD")
    print(f"âš¡ Embedding æ™‚é–“: {end - start:.3f}s")

    return embedding, cost, end - start

# æ¸…é™¤å¿«å–çš„å‡½æ•¸ï¼ˆå¯é¸ï¼‰
def clear_cache():
    global _index_cache, _metadata_cache
    _index_cache.clear()
    _metadata_cache.clear()
    print("ğŸ—‘ï¸ å¿«å–å·²æ¸…é™¤")